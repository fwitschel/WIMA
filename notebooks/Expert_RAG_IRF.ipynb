{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwitschel/WIMA/blob/main/notebooks/Expert_RAG_IRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Execute this code only if in colab\n",
        "if 'COLAB_GPU' in os.environ:\n",
        "  print(\"Executing in Colab!\")\n",
        "  # Cloning GitHub repository\n",
        "  !git clone https://github.com/fwitschel/WIMA.git\n",
        "  %cd WIMA\n"
      ],
      "metadata": {
        "id": "qRHf7ZEBbs5-",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64164e5b-6be4-4327-e531-8dcca7975215"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing in Colab!\n",
            "Cloning into 'QDMKM'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 49 (delta 7), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (49/49), 45.29 KiB | 2.52 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n",
            "/content/QDMKM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oafU1Ii4TXtp"
      },
      "source": [
        "\n",
        "First, we will install required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qh7uQdWfTadO",
        "outputId": "fd65ecfb-12a2-4bec-cfb3-3576f4be1da8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting langchain-anthropic\n",
            "  Downloading langchain_anthropic-0.3.21-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting groq\n",
            "  Downloading groq-0.32.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.28)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.56.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (0.35.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Collecting anthropic<1.0.0,>=0.69.0 (from langchain-anthropic)\n",
            "  Downloading anthropic-0.69.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (0.17.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (0.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.10)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Downloading langchain_community-0.3.30-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.1.1-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.5/323.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_anthropic-0.3.21-py3-none-any.whl (32 kB)\n",
            "Downloading groq-0.32.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.69.0-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, pypdf, mypy-extensions, marshmallow, faiss-cpu, typing-inspect, groq, dataclasses-json, anthropic, langchain-anthropic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anthropic-0.69.0 dataclasses-json-0.6.7 faiss-cpu-1.12.0 groq-0.32.0 langchain-anthropic-0.3.21 langchain-community-0.3.30 marshmallow-3.26.1 mypy-extensions-1.1.0 pypdf-6.1.1 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community pypdf sentence_transformers faiss-cpu langchain-anthropic groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGthazafXj4W",
        "outputId": "54036e59-0d79-4dad-b950-b458dfad7d6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "collapsed": true,
        "id": "X9vaOgI7XvMm",
        "outputId": "7f9e55ab-c6c4-4003-97e2-04513d3182ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 person                                           dc.title  \\\n",
              "0  Grunder, Hans-Ulrich  Der Bildungsforschung die Daten, der Allgemein...   \n",
              "1     Kirnbauer, Martin                                                NaN   \n",
              "2        Hell, Benedikt  Entwicklung eines Interviewleitfadens für die ...   \n",
              "3        Herrmann, Anne  Entwicklung eines Interviewleitfadens für die ...   \n",
              "4        Labudde, Peter  Didaktische Leitfragen für die Lehrerinnen- un...   \n",
              "\n",
              "                        dc.subtitle  \n",
              "0                               NaN  \n",
              "1                               NaN  \n",
              "2                               NaN  \n",
              "3                               NaN  \n",
              "4  Beiträge zur Lehrerbildung (BZL)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f55438b-e662-40b1-8990-640100f8d4e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person</th>\n",
              "      <th>dc.title</th>\n",
              "      <th>dc.subtitle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Grunder, Hans-Ulrich</td>\n",
              "      <td>Der Bildungsforschung die Daten, der Allgemein...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kirnbauer, Martin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hell, Benedikt</td>\n",
              "      <td>Entwicklung eines Interviewleitfadens für die ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Herrmann, Anne</td>\n",
              "      <td>Entwicklung eines Interviewleitfadens für die ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Labudde, Peter</td>\n",
              "      <td>Didaktische Leitfragen für die Lehrerinnen- un...</td>\n",
              "      <td>Beiträge zur Lehrerbildung (BZL)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f55438b-e662-40b1-8990-640100f8d4e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f55438b-e662-40b1-8990-640100f8d4e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f55438b-e662-40b1-8990-640100f8d4e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fd3aa907-74f3-41b8-9e86-6f3c55d61b87\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd3aa907-74f3-41b8-9e86-6f3c55d61b87')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fd3aa907-74f3-41b8-9e86-6f3c55d61b87 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 46511,\n  \"fields\": [\n    {\n      \"column\": \"person\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11356,\n        \"samples\": [\n          \"Perrett, Pieter Jan\",\n          \"Stuchlikova, Iva\",\n          \"Time, Internet\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dc.title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 19107,\n        \"samples\": [\n          \"Alkoholkonsum in der Schweiz: Ergebnisse der ersten schweizerischen Gesundheitsbefragung\",\n          \"Die Zukunft der Organisation - Kann man Teams vertrauen?.\",\n          \"And Then a Miracle Occurs - Engaging the challenge of operationalizing theories of success in digital transformation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dc.subtitle\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 880,\n        \"samples\": [\n          \"Angewandte Chemie Int. Ed.\",\n          \"Thexis - Fachzeitschrift f\\u00fcr Marketing der Universit\\u00e4t St. Gallen\",\n          \"Kaderseminar der Bundeskanzlei, Sigriswil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/IRF_Data.csv', sep=\";\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6LdVecjSqwP"
      },
      "source": [
        "### Parsing the documents\n",
        "First, we will load the csv document and parse it using Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDGqxCpKRuRR",
        "outputId": "01020f10-4fa8-4275-f993-573a4a6e5c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Author: Grunder, Hans-Ulrich, Title: Der Bildungsforschung die Daten, der Allgemeinen Pädagogik die skeptischen RückFragen? Bildungsforschung und Allgemeine Pädagogik' metadata={'source': 'IRF'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "docs = []\n",
        "for index, row in df.iterrows():\n",
        "    person = row['person']\n",
        "    title = row['dc.title']\n",
        "    document = Document(\n",
        "        page_content= \"Author: \" + str(person) + \", Title: \" + str(title),\n",
        "        metadata={\"source\": \"IRF\"}\n",
        "    )\n",
        "    docs.append(document)\n",
        "\n",
        "print(docs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7srp0X7UNTm",
        "outputId": "556a8baf-2b40-4eac-fe00-68a8b844a7bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Grunder, Hans-Ulrich, Title: Der Bildungsforschung die Daten, der Allgemeinen Pädagogik die skeptischen RückFragen? Bildungsforschung und Allgemeine Pädagogik\n"
          ]
        }
      ],
      "source": [
        "print(docs[0].page_content[0:250])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRhvBTARUIJZ"
      },
      "source": [
        "Once we have the text from the document, we have to split it into smaller chunks. We can use LangChain's available splitters, like CharacterTextSplitter in this case:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIv-DbOgUrrG",
        "outputId": "e646930d-6a35-430e-d81d-01a9c19f99a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Author: Grunder, Hans-Ulrich, Title: Der Bildungsforschung die Daten, der Allgemeinen Pädagogik die skeptischen RückFragen? Bildungsforschung und Allgemeine Pädagogik' metadata={'source': 'IRF'}\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=30)\n",
        "chunks = splitter.split_documents(docs)\n",
        "print(chunks[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2Q7BArwVT1J"
      },
      "source": [
        "We will be using BGE-small, an opensource embeddings model. We will download it from HuggingFace Hub and run it on all chunks to calculate their vector representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "cTOW6z0PVYij",
        "outputId": "4e46512d-bd7f-41e4-9d3b-0723eaee339b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1782701561.py:6: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  bge_embeddings = HuggingFaceBgeEmbeddings(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3765a470beb46a29b6c62c05b06c3b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7820087b39544727828e6c7f23e3ea8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46143ac210014ca995204f6343d6dc9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "add412a0a8994d378cbdb1507a9d802c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9861f908bc2f41d2a007d7e94dc1a7aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06eed92c90514f7aa21f7374ff898e9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f84bac712fb4ac092011e3ef9c52793"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7123557f4aef4b378d683c4770a049c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b0ca829fdd14fefa243e26f0a9b28c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5107f04bdc10414aa06d108ab3016e54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50010b9a266147208b8f1deda5d98969"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "model_name = \"BAAI/bge-small-en\"\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "bge_embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "chunk_texts = list(map(lambda d: d.page_content, chunks))\n",
        "embeddings = bge_embeddings.embed_documents(chunk_texts)\n",
        "print(embeddings[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYk2fjOqXTMf"
      },
      "source": [
        "Once we have the vector representations for all chunks, we can create an in-memory vector database and store all vectors in it. For this example, we will be using a FAISS database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1sXZZ3vXTiW"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "text_embedding_pairs = zip(chunk_texts, embeddings)\n",
        "db = FAISS.from_embeddings(text_embedding_pairs, bge_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgsgun3CYNyI"
      },
      "source": [
        "The database is now set up. Now, we will be taking queries from the user on this information. In the case of expert search, we expect the user to ask for an area of expertise. Then, we retrieve the top k most similar chunks to that query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bvp4RbF_YNH-",
        "outputId": "34b28b1b-ddf0-4e2a-edcd-f4ef4bae99d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Göldi, Susan, Title: Big Data Scientist und App-Entwicklerin statt Laternenträger und Kutscher\n",
            "Author: Herzog, Daniel, Title: Big Data Scientist und App-Entwicklerin statt Laternenträger und Kutscher\n",
            "Author: Mareis, Claudia, Title: Datenspuren. Big Data im Kontext von Kultur und Gesellschaft\n",
            "Author: Kilchmann, Daniel, Title: Monitoring statistical data preparation\n",
            "Author: Boes, Stefan (external), Title: The Leaky Pipeline in the Swiss University System: Identifying Gender Barriers in Postgraduate Education and Networks Using Longitudinal Data.\n",
            "Author: Mareis, Claudia, Title: Das Ende der Anschaulichkeit. Künstlerisch-gestalterische Strategien im Umgang mit Big Data\n",
            "Author: Witschel, Hans Friedrich, Title: Data-Mining im KMU - Das Beste aus Daten.\n",
            "Author: Vavouras, Athanasios (external), Title: Data Warehousing: Concepts and Mechanisms.\n",
            "Author: Leemann, Regula Julia, Title: The Leaky Pipeline in the Swiss University System: Identifying Gender Barriers in Postgraduate Education and Networks Using Longitudinal Data.\n",
            "Author: Himmelsbach, Sabine, Title: Das Ende der Anschaulichkeit. Künstlerisch-gestalterische Strategien im Umgang mit Big Data\n",
            "Author: Weishaupt, K (external), Title: Direct Participation Bibliography - Results from a Data Base Research. EPOC Project Working Paper, European Foundation\n",
            "Author: Dubach, Philipp (external), Title: The Leaky Pipeline in the Swiss University System: Identifying Gender Barriers in Postgraduate Education and Networks Using Longitudinal Data.\n",
            "Author: Pekruhl, Ulrich, Title: Direct Participation Bibliography - Results from a Data Base Research. EPOC Project Working Paper, European Foundation\n",
            "Author: Himmelsbach, Sabine, Title: Big Data in the Context of Culture and Society\n",
            "Author: Barjak, Franz, Title: Collection and analysis of existing data on RESearchers CAReers and implementation of new data collection activities (RESCAR)\n",
            "Author: Bendel, Oliver, Title: Big Data\n",
            "Author: Gatziu Grivas, Stella, Title: Data Warehousing: Concepts and Mechanisms.\n",
            "Author: Wettstein, Felix, Title: Die verfehlte Gesundheit im Zeitalter von «Big Data»\n",
            "Author: Mareis, Claudia, Title: Big Data in the Context of Culture and Society\n",
            "Author: Schnabel, A (external), Title: Direct Participation Bibliography - Results from a Data Base Research. EPOC Project Working Paper, European Foundation\n",
            "Author: Reinhard, Evelyn, Title: Visual Analytics in der Modellierung von Lebensführungssystemen. Entwicklung einer Softwareapplikation für die Systemische Diagnostik. Projekt-Abschlussbericht\n",
            "Author: Schuck, B (external), Title: Benefitting from the Data Deluge. How Recent Advances in IT Support Value Creation in Banking.\n",
            "Author: Binder, Karin, Title: Effects of visualizing statistical information – An empirical study on tree diagrams and 2 x 2 tables\n",
            "Author: Wölfle, Ralf, Title: Studie: Bedeutung der Informationstechnologie in der Beschaffung der Top 200 Unternehmen der Schweiz.\n",
            "Author: Eugster, Balthasar (external), Title: Studium und Praktikum - Die Relevanz des informellen und selbstgesteuerten Lernens für die Universität\n",
            "Author: Arnold, Julia, Title: »Denn sie wissen nicht, was sie tun« Educational Data Mining zu Schülervorstellungen im Bereich Methodenwissen\n",
            "Author: Müller, O (external), Title: In-Memory Database Business Value. Results from a Study on Retail Innovation.\n",
            "Author: Prins, Mehrnaz, Title: Visual Analytics in der Modellierung von Lebensführungssystemen. Entwicklung einer Softwareapplikation für die Systemische Diagnostik. Projekt-Abschlussbericht\n",
            "Author: Hulliger, Beat, Title: Monitoring statistical data preparation\n",
            "Author: Hulliger, Beat, Title: Monitoring statistical data preparation\n",
            "Author: Hulliger, Beat, Title: Monitoring statistical data preparation\n",
            "Author: Agotai, Doris, Title: Visual Analytics in der Modellierung von Lebensführungssystemen. Entwicklung einer Softwareapplikation für die Systemische Diagnostik. Projekt-Abschlussbericht\n",
            "Author: Dietsche, Moritz, Title: Visual Analytics in der Modellierung von Lebensführungssystemen. Entwicklung einer Softwareapplikation für die Systemische Diagnostik. Projekt-Abschlussbericht\n",
            "Author: Hohermuth, Beat, Title: Visual Analytics in der Modellierung von Lebensführungssystemen. Entwicklung einer Softwareapplikation für die Systemische Diagnostik. Projekt-Abschlussbericht\n",
            "Author: Vassiliou, Yannis (external), Title: Proceedings 1st International Workshop on Design and Management of Data Warehouses (DMDW).\n",
            "Author: Schock, Ulrike, Title: Visual Analytics in der Modellierung von Lebensführungssystemen. Entwicklung einer Softwareapplikation für die Systemische Diagnostik. Projekt-Abschlussbericht\n",
            "Author: Brügger, A (external), Title: Generalized Graph Matching for Data Mining and Information Retrieval.\n",
            "Author: Hollenstein, Lea, Title: Visual Analytics in der Modellierung von Lebensführungssystemen. Entwicklung einer Softwareapplikation für die Systemische Diagnostik. Projekt-Abschlussbericht\n",
            "Author: Reinhard, Evelyn, Title: Visual Analytics. Software für die Systemische Diagnostik\n",
            "Author: Lehmann, H. (external), Title: Kompetenzentwicklung und kognitive Modellierung in der Betriebsführung der SBB.\n",
            "Author: Lehmann, H. (external), Title: Kompetenzentwicklung und kognitive Modellierung in der Betriebsführung der SBB.\n",
            "Author: Krauss, Stefan, Title: Effects of visualizing statistical information – An empirical study on tree diagrams and 2 x 2 tables\n"
          ]
        }
      ],
      "source": [
        "topk = 42\n",
        "query = \"data science\"\n",
        "\n",
        "contexts = db.similarity_search(query, k=topk)\n",
        "\n",
        "for i in range(topk):\n",
        "  print(contexts[i].page_content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI5rF1aqZJSU"
      },
      "source": [
        "After retrieving the relevant context, we build a prompt using this information and the user's original query. We will use a Llama model via the Huggingface API:\n",
        "\n",
        "\n",
        "\n",
        "> This example uses Huggingface API to call the model. In order for it to work, remember to set the Secret Variable \"HUGGINGFACE_API_KEY\" to your own Huggingface API Key, or change the model to any of your choice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "def llm(groq_client, prompt):\n",
        "  chat_completion = groq_client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "  )\n",
        "\n",
        "  return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "sNoYkKxNbrQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groq_client = Groq(\n",
        "    api_key=userdata.get('GROQ_API_KEY')\n",
        ")"
      ],
      "metadata": {
        "id": "NPimusDPb6OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = '\\n\\n'.join(list(map(lambda c: c.page_content, contexts)))\n",
        "prompt = f\"\"\"You are an assistant that helps users to find people with a certain expertise, based on their publications.\n",
        "You need to analyse the publications and check who has most relevant publications in the given field! The following context contains several relevant publications;\n",
        "for each publication, the author is provided first: {context}. Please only return internal experts!\n",
        "The field that we are interested in is {query}\"\"\"\n",
        "response = llm(groq_client, prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a44INQPHcEAf",
        "outputId": "48283e48-297e-46e4-a3a8-60d40b1aabbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To determine who is an expert in the field of data science, I will analyze the provided publications and identify the authors with the most relevant publications in this field.\n",
            "\n",
            "After analyzing the publications, I found that the following internal authors have published works related to data science:\n",
            "\n",
            "1. Mareis, Claudia (3 publications: \"Datenspuren. Big Data im Kontext von Kultur und Gesellschaft\", \"Das Ende der Anschaulichkeit. Künstlerisch-gestalterische Strategien im Umgang mit Big Data\", \"Big Data in the Context of Culture and Society\")\n",
            "2. Himmelsbach, Sabine (2 publications: \"Das Ende der Anschaulichkeit. Künstlerisch-gestalterische Strategien im Umgang mit Big Data\", \"Big Data in the Context of Culture and Society\")\n",
            "3. Göldi, Susan (1 publication: \"Big Data Scientist und App-Entwicklerin statt Laternenträger und Kutscher\")\n",
            "4. Herzog, Daniel (1 publication: \"Big Data Scientist und App-Entwickelerin statt Laternenträger und Kutscher\")\n",
            "5. Kilchmann, Daniel (1 publication: \"Monitoring statistical data preparation\")\n",
            "6. Witschel, Hans Friedrich (1 publication: \"Data-Mining im KMU - Das Beste aus Daten\")\n",
            "7. Bendel, Oliver (1 publication: \"Big Data\")\n",
            "8. Reinhard, Evelyn (2 publications: \"Visual Analytics in der Modellierung von Lebensführungssystemen. Entwicklung einer Softwareapplikation für die Systemische Diagnostik. Projekt-Abschlussbericht\", \"Visual Analytics. Software für die Systemische Diagnostik\")\n",
            "\n",
            "Based on the number of publications and their relevance to data science, I would recommend the following top experts in the field:\n",
            "\n",
            "1. Mareis, Claudia\n",
            "2. Himmelsbach, Sabine\n",
            "3. Reinhard, Evelyn\n",
            "\n",
            "These authors have demonstrated a strong focus on data science and related topics, with multiple publications in the field.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
